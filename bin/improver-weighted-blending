#!/usr/bin/env python
# -*- coding: utf-8 -*-
# -----------------------------------------------------------------------------
# (C) British Crown Copyright 2017-2018 Met Office.
# All rights reserved.
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions are met:
#
# * Redistributions of source code must retain the above copyright notice, this
#   list of conditions and the following disclaimer.
#
# * Redistributions in binary form must reproduce the above copyright notice,
#   this list of conditions and the following disclaimer in the documentation
#   and/or other materials provided with the distribution.
#
# * Neither the name of the copyright holder nor the names of its
#   contributors may be used to endorse or promote products derived from
#   this software without specific prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
# POSSIBILITY OF SUCH DAMAGE.

"""Script to run weighted blending."""

import iris
import numpy as np
from cf_units import Unit

from improver.argparser import ArgParser
from improver.utilities.load import load_cubelist
from improver.utilities.save import save_netcdf
from improver.utilities.cube_manipulation import merge_cubes
from improver.utilities.temporal import (
    forecast_period_coord, unify_forecast_reference_time)
#from improver.utilities.cube_metadata import update_cube_blended_metadata

from improver.blending.weights import (
    ChooseDefaultWeightsLinear, ChooseDefaultWeightsNonLinear)
from improver.blending.weighted_blend import (
    WeightedBlendAcrossWholeDimension, conform_metadata)


def main():
    """Load in arguments and ensure they are set correctly.
       Then load in the data to blend and calculate default weights
       using the method chosen before carrying out the blending."""
    parser = ArgParser(
        description='Calculate the default weights to apply in weighted '
        'blending plugins using the ChooseDefaultWeightsLinear or '
        'ChooseDefaultWeightsNonLinear plugins. Then apply these '
        'weights to the dataset using the BasicWeightedAverage plugin.'
        ' Required for ChooseDefaultWeightsLinear: y0val and ynval.'
        ' Required for ChooseDefaultWeightsNonLinear: cval.')
    parser.add_argument('--wts_calc_method',
                        metavar='WEIGHTS_CALCULATION_METHOD',
                        choices=['linear', 'nonlinear'],
                        default='linear',
                        help='Method to use to calculate weights used in '
                             'blending. "linear" (default): calculate linearly'
                             ' varying blending weights. "nonlinear": '
                             'calculate blending weights that decrease '
                             'exponentially with increasing blending '
                             'coordinate.')
    parser.add_argument('coordinate', type=str,
                        metavar='COORDINATE_TO_AVERAGE_OVER',
                        help='The coordinate over which the blending '
                             'will be applied.')
    parser.add_argument('--coordinate_unit', metavar='UNIT_STRING',
                        default='hours since 1970-01-01 00:00:00',
                        help='Units for blending coordinate. Default= '
                             'hours since 1970-01-01 00:00:00')
    parser.add_argument('--calendar', metavar='CALENDAR',
                        help='Calendar for time coordinate. Default=gregorian')
    parser.add_argument('weighting_mode', metavar='WEIGHTED_BLEND_MODE',
                        choices=['weighted_mean', 'weighted_maximum'],
                        help='The method used in the weighted blend. '
                             '"weighted_mean": calculate a normal weighted'
                             ' mean across the coordinate. '
                             '"weighted_maximum": multiplies the values in the'
                             ' coordinate by the weights, and then takes the'
                             ' maximum.')
    parser.add_argument('input_filepaths', metavar='INPUT_FILES',
                        nargs="+",
                        help='Paths to input files to be blended.')
    parser.add_argument('output_filepath', metavar='OUTPUT_FILE',
                        help='The output path for the processed NetCDF.')

    linear = parser.add_argument_group('linear weights options',
                                       'Options for the linear weights '
                                       'calculation in '
                                       'ChooseDefaultWeightsLinear')
    linear.add_argument('--ynval', metavar='LINEAR_END_POINT',
                          type=float,
                          help='The relative value of the weighting end '
                               'point for choosing default linear weights.')
    linear.add_argument('--y0val', metavar='LINEAR_STARTING_POINT', type=float,
                        help='The relative value of the weighting start '
                             'point for choosing default linear weights. '
                             'This must be a positive float or 0. If not set, '
                             'default values of y0val=20.0 and ynval=2.0 '
                             'are set.')
    nonlinear = parser.add_argument_group('nonlinear weights options',
                                          'Options for the non-linear '
                                          'weights calculation in '
                                          'ChooseDefaultWeightsNonLinear')
    nonlinear.add_argument('--cval', metavar='NON_LINEAR_FACTOR', type=float,
                           help='Factor used to determine how skewed the '
                                'non linear weights will be. '
                                'A value of 1 implies equal weighting. If not '
                                'set, a default value of cval=0.85 is set.')
    parser.add_argument('--cycletime', metavar='CYCLETIME', type=str,
                        help='The forecast_reference_time to be used after '
                             'blending has been applied in the format '
                             'YYYYMMDDTHHMMZ.')
    args = parser.parse_args()

    # if the linear weights method is called with non-linear args or vice
    # versa, exit with error
    if (args.wts_calc_method == "linear") and args.cval:
        parser.wrong_args_error('cval', 'linear')
    elif ((args.wts_calc_method == "nonlinear") and
          np.any([args.y0val, args.ynval])):
        parser.wrong_args_error('y0val, ynval', 'non-linear')

    # set blending coordinate units
    if "time" in args.coordinate:
        coord_unit = Unit(args.coordinate_unit, args.calendar)
    elif args.coordinate_unit != 'hours since 1970-01-01 00:00:00.':
        coord_unit = args.coordinate_unit
    else:
        coord_unit = 'no_unit'

    # load and merge cubes to be blended
    cubelist = load_cubelist(args.input_filepaths)
    cube = merge_cubes(cubelist)

    # if the coord for blending does not exist or has only one value,
    # no processing is needed
    coord_names = [coord.name() for coord in cube.coords()]
    if (args.coordinate not in coord_names) or (
            len(cube.coord(args.coordinate).points) == 1):
        result = cube.copy()
        conform_metadata(result, cube, args.coordinate)

    # otherwise blend across specified dimension
    else:
        # if blending across forecast_reference_time, check the
        # forecast period coordinate exists and add if necessary
        if "forecast_reference_time" in args.coordinate:
            coord_names = [x.name() for x in cube.coords()]
            frt_dim, = cube.coord_dims(args.coordinate)
            if "forecast_period" not in coord_names:
                forecast_period = forecast_period_coord(cube)
                cube.add_aux_coord(forecast_period, data_dims=frt_dim)

        # if blending across forecast period, unify forecast reference
        # times for different models
        if "forecast_period" in args.coordinate:
            cubes = unify_forecast_reference_time(cube)
            cube = merge_cubes(cubes)

        # blend according to user-specified method
        if args.wts_calc_method == "linear":
            weights = ChooseDefaultWeightsLinear(
                y0val=args.y0val, ynval=args.ynval).process(
                    cube, args.coordinate, coord_unit=coord_unit)
        else:
            cval = args.cval if args.cval else 0.85
            weights = ChooseDefaultWeightsNonLinear(cval).process(
                cube, args.coordinate, coord_unit=coord_unit)

        BlendingPlugin = WeightedBlendAcrossWholeDimension(
            args.coordinate, args.weighting_mode,
            cycletime=args.cycletime)
        result = BlendingPlugin.process(cube, weights)

    save_netcdf(result, args.output_filepath)


if __name__ == "__main__":
    main()
