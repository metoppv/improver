#!/usr/bin/env python
# -*- coding: utf-8 -*-
# -----------------------------------------------------------------------------
# (C) British Crown Copyright 2017-2018 Met Office.
# All rights reserved.
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions are met:
#
# * Redistributions of source code must retain the above copyright notice, this
#   list of conditions and the following disclaimer.
#
# * Redistributions in binary form must reproduce the above copyright notice,
#   this list of conditions and the following disclaimer in the documentation
#   and/or other materials provided with the distribution.
#
# * Neither the name of the copyright holder nor the names of its
#   contributors may be used to endorse or promote products derived from
#   this software without specific prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
# POSSIBILITY OF SUCH DAMAGE.

"""Script to run weighted blending."""

import numpy as np
import json
import iris
import warnings
from cf_units import Unit

from improver.argparser import ArgParser
from improver.utilities.load import load_cubelist
from improver.utilities.save import save_netcdf
from improver.utilities.cube_manipulation import (
    merge_cubes, sort_coord_in_cube)

from improver.blending.weights import (
    ChooseWeightsLinear, ChooseDefaultWeightsLinear,
    ChooseDefaultWeightsNonLinear)
from improver.blending.weighted_blend import (
    conform_metadata, rationalise_blend_time_coords,
    WeightedBlendAcrossWholeDimension)


def calculate_blending_weights(cube, blend_coord, method, wts_dict=None,
                               weighting_coord=None, wts_mask_constraint=None,
                               coord_unit=None, y0val=None, ynval=None,
                               cval=None):
    """
    Wrapper for plugins to calculate blending weights using the command line
    options specified.

    Args:
        cube (iris.cube.Cube):
            Cube of input data to be blended
        blend_coord (str):
            Coordinate over which blending will be performed (eg "model" for
            grid blending)
        method (str):
            Weights calculation method ("linear", "nonlinear", "dict" or
            "mask")

    Kwargs:
        wts_dict (str):
            File path to json file with parameters for linear weights
            calculation
        weighting_coord (str):
            Coordinate over which linear weights should be calculated from dict
        wts_mask_constraint (str or iris.Constraint):
            Optional constraint for identifying the masked cube from which to
            calculate spatially varying blend weights.
        coord_unit (str or cf_units.Unit):
            Unit of blending coordinate (for default weights plugins)
        y0val (float):
            Intercept parameter for default linear weights plugin
        ynval (float):
            Gradient parameter for default linear weights plugin
        cval (float):
            Parameter for default non-linear weights plugin

    Returns:
        weights (np.ndarray):
            1D array of weights corresponding to slices in ascending order
            of blending coordinate.  (Note: ChooseLinearWeights has the
            option to create a 3D array of spatially-varying weights with the
            "mask" option, however this is not currently supported by the
            blending plugin.)
    """
    # sort input cube by blending coordinate
    cube = sort_coord_in_cube(cube, blend_coord, order="ascending")

    # calculate blending weights
    if method == "dict":
        # calculate linear weights from a dictionary
        with open(wts_dict, 'r') as wts:
            weights_dict = json.load(wts)
        weights_cube = ChooseWeightsLinear(
            weighting_coord, config_coord_name=blend_coord,
            config_dict=weights_dict).process(cube)

        # if wts_mask_constraint is specified, use cube mask to determine
        # spatially varying weights and combine with dictionary-derived
        # weights cube to create final weights cube
        if wts_mask_constraint is not None:
            # NOTE this functionality is not yet coded, so raise a warning
            warnings.warn('Calculation of spatially varying weights is '
                          'not yet supported - using dict only')

        # sort weights cube by blending coordinate and extract
        # data array as input to blending plugin
        weights = sort_coord_in_cube(
            weights_cube, blend_coord, order="ascending").data

    elif method == "linear":
        weights = ChooseDefaultWeightsLinear(
            y0val=y0val, ynval=ynval).process(
                cube, blend_coord, coord_unit=coord_unit)

    elif method == "nonlinear":
        # this is set here rather than in the CLI arguments in order to check
        # for invalid argument combinations
        cvalue = cval if cval else 0.85
        weights = ChooseDefaultWeightsNonLinear(cvalue).process(
            cube, blend_coord, coord_unit=coord_unit)

    return weights


def main():
    """Load in arguments and ensure they are set correctly.
       Then load in the data to blend and calculate default weights
       using the method chosen before carrying out the blending."""
    parser = ArgParser(
        description='Calculate the default weights to apply in weighted '
        'blending plugins using the ChooseDefaultWeightsLinear or '
        'ChooseDefaultWeightsNonLinear plugins. Then apply these '
        'weights to the dataset using the BasicWeightedAverage plugin.'
        ' Required for ChooseDefaultWeightsLinear: y0val and ynval.'
        ' Required for ChooseDefaultWeightsNonLinear: cval.'
        ' Required for ChooseWeightsLinear with dict: wts_dict.')

    parser.add_argument('--wts_calc_method',
                        metavar='WEIGHTS_CALCULATION_METHOD',
                        choices=['linear', 'nonlinear', 'dict'],
                        default='linear', help='Method to use to calculate '
                        'weights used in blending. "linear" (default): '
                        'calculate linearly varying blending weights. '
                        '"nonlinear": calculate blending weights that decrease'
                        ' exponentially with increasing blending coordinate. '
                        '"dict": calculate weights using a dictionary passed '
                        'in as a command line argument.')

    parser.add_argument('coordinate', type=str,
                        metavar='COORDINATE_TO_AVERAGE_OVER',
                        help='The coordinate over which the blending '
                             'will be applied.')
    parser.add_argument('--coordinate_unit', metavar='UNIT_STRING',
                        default='hours since 1970-01-01 00:00:00',
                        help='Units for blending coordinate. Default= '
                             'hours since 1970-01-01 00:00:00')
    parser.add_argument('--calendar', metavar='CALENDAR',
                        help='Calendar for time coordinate. Default=gregorian')
    parser.add_argument('--cycletime', metavar='CYCLETIME', type=str,
                        help='The forecast reference time to be used after '
                        'blending has been applied, in the format '
                        'YYYYMMDDTHHMMZ. If not provided, the blended file '
                        'will take the latest available forecast reference '
                        'time from the input cubes supplied.')

    parser.add_argument('weighting_mode', metavar='WEIGHTED_BLEND_MODE',
                        choices=['weighted_mean', 'weighted_maximum'],
                        help='The method used in the weighted blend. '
                             '"weighted_mean": calculate a normal weighted'
                             ' mean across the coordinate. '
                             '"weighted_maximum": multiplies the values in the'
                             ' coordinate by the weights, and then takes the'
                             ' maximum.')

    parser.add_argument('input_filepaths', metavar='INPUT_FILES',
                        nargs="+",
                        help='Paths to input files to be blended.')
    parser.add_argument('output_filepath', metavar='OUTPUT_FILE',
                        help='The output path for the processed NetCDF.')

    linear = parser.add_argument_group('linear weights options',
                                       'Options for the linear weights '
                                       'calculation in '
                                       'ChooseDefaultWeightsLinear')
    linear.add_argument('--y0val', metavar='LINEAR_STARTING_POINT', type=float,
                        help='The relative value of the weighting start point '
                        '(lowest value of blend coord) for choosing default '
                        'linear weights. This must be a positive float or 0.')
    linear.add_argument('--ynval', metavar='LINEAR_END_POINT',
                        type=float, help='The relative value of the weighting '
                        'end point (highest value of blend coord) for choosing'
                        ' default linear weights. This must be a positive '
                        'float or 0.  Note that if blending over forecast '
                        'reference time, ynval >= y0val would normally be '
                        'expected (to give greater weight to the more recent '
                        'forecast).')

    nonlinear = parser.add_argument_group('nonlinear weights options',
                                          'Options for the non-linear '
                                          'weights calculation in '
                                          'ChooseDefaultWeightsNonLinear')
    nonlinear.add_argument('--cval', metavar='NON_LINEAR_FACTOR', type=float,
                           help='Factor used to determine how skewed the '
                                'non linear weights will be. '
                                'A value of 1 implies equal weighting. If not '
                                'set, a default value of cval=0.85 is set.')

    wts_dict = parser.add_argument_group('dict weights options',
                                         'Options for linear weights to be '
                                         'calculated based on parameters '
                                         'read from a json file dict')
    wts_dict.add_argument('--wts_dict', metavar='WEIGHTS_DICTIONARY',
                          help='Path to json file containing dictionary from '
                          'which to calculate blending weights. Dictionary '
                          'format is as specified in the improver.blending.'
                          'weights.ChooseWeightsLinear plugin.')
    wts_dict.add_argument('--weighting_coord', metavar='WEIGHTING_COORD',
                          default='forecast_period', help='Name of '
                          'coordinate over which linear weights should be '
                          'scaled. This coordinate must be avilable in the '
                          'weights dictionary.')
    wts_dict.add_argument('--wts_mask_constraint',
                          metavar='WEIGHTS_MASK_CONSTRAINT', help='Optional '
                          'constraint by which to identify an input cube whose'
                          ' mask should be used to calculate spatially varying'
                          ' blending weights. These are then scaled along the '
                          'weighting coordinate using the dictionary derived '
                          'weights.')

    args = parser.parse_args()

    # if the linear weights method is called with non-linear args or vice
    # versa, exit with error
    if (args.wts_calc_method == "linear") and args.cval:
        parser.wrong_args_error('cval', 'linear')
    if ((args.wts_calc_method == "nonlinear") and np.any([args.y0val,
                                                          args.ynval])):
        parser.wrong_args_error('y0val, ynval', 'non-linear')
    if (args.wts_calc_method == "dict") and not args.wts_dict:
        parser.error('Dictionary is required if --wts_calc_method="dict"')

    # set blending coordinate units
    if "time" in args.coordinate:
        coord_unit = Unit(args.coordinate_unit, args.calendar)
    elif args.coordinate_unit != 'hours since 1970-01-01 00:00:00.':
        coord_unit = args.coordinate_unit
    else:
        coord_unit = 'no_unit'

    # load cubes to be blended
    cubelist = load_cubelist(args.input_filepaths)

    # determine whether or not to equalise forecast periods for model
    # blending weights calculation
    weighting_coord = (args.weighting_coord if args.weighting_coord
                       else "forecast_period")

    # ensure time coordinates are blendable
    rationalise_blend_time_coords(
        cubelist, args.coordinate, cycletime=args.cycletime,
        weighting_coord=weighting_coord)

    # merge cube list
    cube = merge_cubes(cubelist)

    # if the coord for blending does not exist or has only one value,
    # update metadata only
    coord_names = [coord.name() for coord in cube.coords()]
    if (args.coordinate not in coord_names) or (
            len(cube.coord(args.coordinate).points) == 1):
        result = cube.copy()
        conform_metadata(
            result, cube, args.coordinate, cycletime=args.cycletime)
        # raise a warning if this happened because the blend coordinate
        # doesn't exist
        if args.coordinate not in coord_names:
            warnings.warn('Blend coordinate {} is not present on input '
                          'data'.format(args.coordinate))

    # otherwise, calculate weights and blend across specified dimension
    else:
        weights = calculate_blending_weights(
            cube, args.coordinate, args.wts_calc_method,
            wts_dict=args.wts_dict, weighting_coord=args.weighting_coord,
            wts_mask_constraint=args.wts_mask_constraint,
            coord_unit=coord_unit, y0val=args.y0val, ynval=args.ynval,
            cval=args.cval)

        # blend across specified dimension
        BlendingPlugin = WeightedBlendAcrossWholeDimension(
            args.coordinate, args.weighting_mode,
            cycletime=args.cycletime)
        result = BlendingPlugin.process(cube, weights=weights)

    save_netcdf(result, args.output_filepath)


if __name__ == "__main__":
    main()
