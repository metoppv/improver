#!/usr/bin/env python
# -*- coding: utf-8 -*-
# -----------------------------------------------------------------------------
# (C) British Crown Copyright 2017-2018 Met Office.
# All rights reserved.
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions are met:
#
# * Redistributions of source code must retain the above copyright notice, this
#   list of conditions and the following disclaimer.
#
# * Redistributions in binary form must reproduce the above copyright notice,
#   this list of conditions and the following disclaimer in the documentation
#   and/or other materials provided with the distribution.
#
# * Neither the name of the copyright holder nor the names of its
#   contributors may be used to endorse or promote products derived from
#   this software without specific prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
# POSSIBILITY OF SUCH DAMAGE.
"""Script to standardise a NetCDF file by one or more of regridding, updating
meta-data and demoting float64 data to float32"""

import iris
import json

from improver.argparser import ArgParser
from improver.utilities.load import load_cube
from improver.utilities.save import save_netcdf
from improver.utilities.cube_checker import check_cube_not_float64
from improver.utilities.cube_metadata import amend_metadata


def main():
    """Standardise a source cube. Standardisation options include regridding
    (with options to fix float64 data, use Iris nearest and extrapolate
    modes and update metadata. Standalone options included checking/fixing
    float64 data and updating metadata. A check for float64 data compliance
    can be made by only specify a source NetCDF file with no
    other arguments."""
    parser = ArgParser(
        description='Standardise a source data cube. Three main options are '
                    'available; checking and optionally fixing float64 data, '
                    'regridding and updating metadata. If regridding then '
                    'additional options are available to specify Iris nearest '
                    'and extrapolation modes. If only a source file is '
                    'specified with no other arguments, then an exception '
                    'will be raised if float64 data is found on the source.')

    parser.add_argument('source_data_filepath', metavar='SOURCE_DATA',
                        help='A cube of data that is to be standardised and '
                             'optionally fixed for float64 data, regridded '
                             'and meta data changed')

    parser.add_argument("--output_filepath", metavar="OUTPUT_FILE",
                        default=None,
                        help="The output path for the processed NetCDF. "
                             "If only a source file is specified and no "
                             "output file, then the source will be checked"
                             "for float64 data.")

    parser.add_argument("--target_grid_filepath", metavar="TARGET_GRID",
                        help='If specified then regridding of the source '
                             'against the target grid is enabled.')

    parser.add_argument("--fix_float64", action='store_true', default=False,
                        help="Check and fix cube for float64 data. Without "
                             "this option an exception will be raised if "
                             "float64 data is found but no fix applied.")

    parser.add_argument("--nearest", action='store_true', default=False,
                        help='If True, regridding will be performed using '
                             'iris.analysis.Nearest() instead of Linear(). '
                             'Use for less continuous fields, '
                             'e.g. precipitation.')

    parser.add_argument("--extrapolation_mode", default='nanmask',
                        help='Mode to use for extrapolating data into regions '
                             'beyond the limits of the source_data domain. '
                             'Modes are: '
                             'extrapolate - The extrapolation points will '
                             'take their value from the nearest source point. '
                             'nan - The extrapolation points will be be '
                             'set to NaN. '
                             'error - A ValueError exception will be raised, '
                             'notifying an attempt to extrapolate. '
                             'mask  - The extrapolation points will always be '
                             'masked, even if the source data is not a '
                             'MaskedArray. '
                             'nanmask - If the source data is a MaskedArray '
                             'the extrapolation points will be masked. '
                             'Otherwise they will be set to NaN. '
                             'Defaults to nanmask.')

    parser.add_argument("--json_file", metavar="JSON_FILE", default=None,
                        help='Filename for the json file containing required '
                             'changes that will be applied '
                             'to the metadata. Defaults to None.')

    args = parser.parse_args()

    # source file data path is a mandatory argument
    output_data = load_cube(args.source_data_filepath)

    if args.fix_float64:
        check_cube_not_float64(output_data, fix=True)
    else:
        check_cube_not_float64(output_data, fix=False)

    if args.target_grid_filepath or args.json_file or args.fix_float64:
        if not args.output_filepath:
            msg = ("An argument has been specified that requires an output "
                   "filepath but none has been provided")
            raise ValueError(msg)

    # Re-grid with options:
    # if a target grid file has been specified, then regrid optionally
    # applying float64 data check, metadata change, Iris nearest and
    # extrapolation mode as required.

    if args.target_grid_filepath:

        target_grid = load_cube(args.target_grid_filepath)

        regridder = iris.analysis.Linear(
            extrapolation_mode=args.extrapolation_mode)

        if args.nearest:
            regridder = iris.analysis.Nearest(
                extrapolation_mode=args.extrapolation_mode)

        output_data = output_data.regrid(target_grid, regridder)

        target_grid_attributes = (
            {k: v for (k, v) in target_grid.attributes.items()
             if 'mosg__' in k or 'institution' in k})
        amend_metadata(output_data, attributes=target_grid_attributes)

    # Change metadata only option:
    # if output file path and json metadata file specified,
    # change the metadata
    if args.json_file:
        with open(args.json_file, 'r') as input_file:
            metadata_dict = json.load(input_file)
        output_data = amend_metadata(output_data, **metadata_dict)

    # Check and fix for float64 data only option:
    if args.fix_float64:
        check_cube_not_float64(output_data, fix=True)

    if args.output_filepath:
        save_netcdf(output_data, args.output_filepath)


if __name__ == "__main__":
    main()
